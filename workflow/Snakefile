from snakemake.utils import min_version

min_version("6.10.0")

# Configuration file containing all user-specified settings
configfile: "config/config.yaml"


import os
import csv
import pandas as pd

METADATA=pd.read_csv('data/metadata/metadata.csv').loc[0:3]
ACCESSIONS=METADATA['Run'].tolist()
OUTDIR="data/reads" 
TEMPDIR="data/temp"

if not os.path.exists(OUTDIR):
   os.makedirs(OUTDIR)

if not os.path.exists(TEMPDIR):
   os.makedirs(TEMPDIR)

# Master rule for controlling workflow.
rule all:
    input:
        # "data/metadata/sra_accessions.txt",
        # expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
        expand("data/reads/{accession}_{sraNum}.fastq.gz", accession=ACCESSIONS, sraNum=config["sraNum"]),
        "index.html"


# Dowload the SRA RUN reads
rule fasterq_dump_sra_reads: 
    output:
        "data/reads/{accession}_{sraNum}.fastq",
    params:
        outfolder=OUTDIR,
        temp=TEMPDIR,
    threads: 1
    shell:
        """
        fasterq-dump \
        --split-3 \
        --force \
        --skip-technical {wildcards.accession} \
        --outdir {params.outfolder} \
        --temp {params.temp} \
        --threads {threads}
        """

rule gzip_fastq_files: 
    input:
        script="workflow/scripts/get_zipped_fastq.sh",
        reads=expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
    output:
        "data/reads/{accession}_{sraNum}.fastq.gz",
    shell:
        "bash {input.script}"


# # # # Subset a test data
# # # rule seqkit_subset_fastq:
# # #     input:
# # #         expand("data/reads/{accession}_1.fastq", accession=ACCESSIONS),
# # #         expand("data/reads/{accession}_2.fastq", accession=ACCESSIONS),
# # #     output:
# # #         "data/test/{accession}_1_sub.fastq",
# # #         "data/test/{accession}_2_sub.fastq",
# # #     threads: 1
# # #     shell:
# # #         """
# # #         bash workflow/scripts/subset_fastq.sh
# # #         """


# # # rule seqkit_simple_stats:
# # #     input:
# # #         script="workflow/scripts/seqkit_stat_1.sh",
# # #         rawreads=expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
# # #     output:
# # #         seqkit1="results/stats1/seqkit_stats.txt",
# # #     threads: 1
# # #     shell:
# # #       "bash {input.script}"


# # # rule mothur_mapping_file:
# # #     input:
# # #         stats1="results/stats1/seqkit_stats.txt"
# # #     output:
# # #         files="data/metadata/mothur_mapping_file.tsv",
# # #     threads: 1
# # #     script:
# # #       "scripts/mothur_mapping_file.R"


# # # rule mothur_design_file:
# # #     input:
# # #         files="data/metadata/mothur_mapping_file.tsv",
# # #     output:
# # #         files="data/metadata/mothur_design_file.tsv",
# # #     threads: 1
# # #     script:
# # #       "scripts/mothur_design_file.R"

# # # # Downloading and formatting SILVA and RDP reference databases. The v4 region is extracted from 
# # # # SILVA database for use as reference alignment.
# # # rule mothur_references:
# # # 	input:
# # # 		script="workflow/scripts/mothurReferences.sh"
# # # 	output:
# # # 		silvaV4="data/mothur/references/silva.v4.align",
# # # 		rdpFasta="data/mothur/references/trainset16_022016.pds.fasta",
# # # 		rdpTax="data/mothur/references/trainset16_022016.pds.tax"
# # # 	conda:
# # # 		"envs/mothur.yaml"
# # # 	shell:
# # # 		"bash {input.script}"


# # # # Downloading the Zymo mock sequence files and extracting v4 region for error estimation.
# # # rule mothur_zymo_mock:
# # # 	input:
# # # 		script="workflow/scripts/mothurMock.sh",
# # # 		silvaV4="data/mothur/references/silva.v4.align",
# # # 	output:
# # # 		mockV4="data/mothur/references/zymo.mock.16S.v4.fasta"
# # # 	conda:
# # # 		"envs/mothur.yaml"
# # # 	shell:
# # # 		"bash {input.script}"


# # # rule gather_bioinfo_resources:
# # #     shell:
# # #         """
# # #         bash workflow/scripts/get_bioinfo_resources.sh
# # #         """





# Get dot rule graphs
rule dot_rules_graph:
	output:
		"dags/rulegraph.svg",
		"dags/rulegraph.png",
	shell:
		"bash workflow/scripts/rules_dag.sh"


# Get project tree
rule project_tree:
    output:
        tree="results/project_tree.txt"
    shell:
        """
        bash workflow/scripts/tree.sh
        """

# Get smk static report
rule static_snakemake_report:
    output:
        smkhtml="report.html",
        html2png="images/smkreport/screenshot.png"
    shell:
        """
        bash workflow/scripts/smk_html_report.sh
        """

rule deploy_to_github_pages:
    input:
        script="workflow/scripts/render.R",
        rmd="index.Rmd",
        tree="results/project_tree.txt",
        html2png=rules.static_snakemake_report.output.html2png,
        rules="dags/rulegraph.svg",
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('{input.rmd}')"
        """